{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6ad57b-45ad-4eb8-9e73-976bf2587bb2",
   "metadata": {},
   "source": [
    "## Previously on Audio Processing for ML\n",
    "\n",
    "<ul>\n",
    "    <li>Time-domain features</li>\n",
    "    <li>Frequency-domain features</li>\n",
    "    <li>Time-frequency domain features</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"../images/signal_domain.png\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>Time Domain Feature Pipeline</h2>\n",
    "In audio processing, a <b>frame is a short segment</b> of a signal used for analysis or feature extraction.\n",
    "\n",
    "<img src=\"../images/time_domain_feature_pipeline_2.png\">\n",
    "<hr>\n",
    "\n",
    "In the image:\n",
    "\n",
    "<ul>\n",
    "    <li>A violin produces a <b>continuous</b> analog sound wave.</li>\n",
    "    <li>The waveform is <b>sampled and quantized</b>, converting it to a digital signal (blue stair-step line).</li>\n",
    "    <li>This digital signal is divided into <b>overlapping frames</b> — short, fixed-size segments.</li>\n",
    "</ul>\n",
    "<hr>\n",
    "As we covered before,\n",
    "\n",
    "<b>Key Concepts in Framing:</b>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Frame Size:</b> Number of samples per frame (e.g., 128 samples).</li>\n",
    "    <li><b>Hop Size:</b> Step size to move to the next frame (e.g., 64 samples).</li>\n",
    "    <li><b>Overlap:</b> How much the frames overlap. For example, a frame size of 128 with a hop size of 64 results in a 50% overlap.</li>\n",
    "</ul>\n",
    "<hr>\n",
    "\n",
    "<h3>Why Use Framing?</h3>\n",
    "\n",
    "<ul>\n",
    "    <li>Audio signals change over time, so processing the whole signal at once may <b>lose time-specific details.</b></li>\n",
    "    <li>Frames allow <b>time-localized analysis</b> — useful in speech, music, and general sound analysis (e.g., computing MFCCs, spectrograms).</li>\n",
    "</ul>\n",
    "\n",
    "We will cover this after a while\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f5cb6-f105-49fa-9c5b-557e2a929d13",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<h2>Perceivable audio chunk for humans</h2>\n",
    "\n",
    "<b>Human auditory system</b> cannot perceive as meaningful audio (tone, pitch, loudness, or even detect a transient) features on its own from a sample point, it requires a chunk of audio samples with a temporal resolution of about 10 milliseconds — this means we can distinguish changes in sound that happen around or above this time scale.\n",
    "\n",
    "<hr>\n",
    "<b>A power of 2 num. Samples</b>\n",
    "\n",
    "We often choose frame sizes (number of samples) as powers of 2 specifically to optimize the performance of the Fast Fourier Transform (FFT).\n",
    "\n",
    "\n",
    "<h3>Why Powers of 2?</h3>\n",
    "<ul>\n",
    "    <li><b>The Fast Fourier Transform (FFT)</b> is an efficient algorithm for computing the <b>Discrete Fourier Transform (DFT)</b>.</li>\n",
    "    <li>The most widely used <b>FFT algorithm (Cooley–Tukey)</b> is fastest when the number of input samples is a power of 2:</li>\n",
    "    <center>\n",
    "\n",
    "$$\n",
    "N = 2^n \\quad \\text{(e.g., } N = 256,\\, 512,\\, 1024,\\, 2048 \\text{)}\n",
    "$$\n",
    "\n",
    "</center>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "Let:\n",
    "\n",
    "- $( d_f )$: frame duration (in seconds)\n",
    "- $( s_r )$: sampling rate (e.g., 44100 Hz)\n",
    "- $( K )$: number of samples per frame (e.g., 512)\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "d_f = \\frac{1}{s_r} \\cdot K = \\frac{1}{44100} \\cdot 512 \\approx 11.6\\ \\text{ms}\n",
    "$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "| Power-of-2 | Samples per Frame | Duration @ 44.1kHz | Use Case                                         |\n",
    "|------------|-------------------|--------------------|--------------------------------------------------|\n",
    "| 256        | 256               | ~5.8 ms            | Good time resolution                             |\n",
    "| 512        | 512               | ~11.6 ms           | Balance of time and frequency                    |\n",
    "| 1024       | 1024              | ~23.2 ms           | Better frequency resolution                      |\n",
    "| 2048       | 2048              | ~46.4 ms           | High frequency resolution, worse time resolution |\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf78ef-d752-4f5c-ad0c-08ecb229fe3a",
   "metadata": {},
   "source": [
    "<h2>Frequency-domain feature pipeline</h2>\n",
    "<hr>\n",
    "<img src=\"../images/frequency_domain.png\">\n",
    "<hr>\n",
    "<h2>From Time to Frequency Domain</h2>\n",
    "<hr>\n",
    "<img src=\"../images/from_time_to_frequency.png\">\n",
    "<hr>\n",
    "\n",
    "<h2>What Is Spectral Leakage?</h2>\n",
    "\n",
    "Spectral leakage happens when a <b>non-periodic signal (within a frame)</b> is processed using the Discrete Fourier Transform (DFT) or FFT.\n",
    "\n",
    "<hr>\n",
    "<h2>Why Does It Arise?</h2>\n",
    "<b>\n",
    "1. Fourier transform assumes periodicity\n",
    "</b>\n",
    "<ul>\n",
    "    <li><b>DFT/FFT</b> assumes that the signal you're analyzing <b>repeats forever.</b></li>\n",
    "    <li>But when you take a <b>finite frame/window</b>, the signal may <b>not complete a whole cycle.</b></li>\n",
    "    <li>The <b>edges</b> of the <b>frame</b> are often <b>discontinuous</b>, breaking the illusion of periodicity.</li>\n",
    "</ul>\n",
    "\n",
    "<b>\n",
    "    2. Discontinuities = Artificial high-frequency components\n",
    "</b>\n",
    "<ul>\n",
    "    <li>At the <b>endpoints</b> of the frame, if the signal <b>doesn’t smoothly wrap around</b>, a jump (<b>discontinuity</b>) appears.</li>\n",
    "    <li>These <b>jumps</b> get interpreted by the Fourier transform as <b>broadband high-frequency content.</b></li>\n",
    "    <li>These are <b>not real</b> — they’re <b>artifacts.</b></li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>Example (Violin waveform):</h2>\n",
    "\n",
    "Let’s say a violin plays a note of 440 Hz (A4).\n",
    "\n",
    "If your frame captures 1.2 periods, the waveform starts at one point and ends somewhere random — not matching the start of the next cycle.\n",
    "\n",
    "<ul>\n",
    "    <li>The FFT sees that as a signal with many frequencies.</li>\n",
    "    <li>So instead of a sharp peak at 440 Hz, you get \"leakage\" into nearby bins (e.g., 430, 450 Hz etc.)</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>Solutions to Reduce Leakage:</h2>\n",
    "\n",
    "1. <b>Windowing functions</b> (e.g., Hamming, Hann, Blackman):\n",
    "    <ul>\n",
    "        <li>Smooth the signal edges to zero to reduce sharp discontinuities.</li>\n",
    "        <li>Reduces spectral leakage — though may trade off resolution.</li>\n",
    "    </ul>\n",
    "\n",
    "2. Choose frame size to match signal periodicity (if known)\n",
    "3. <b>Zero-padding</b> (sometimes helps for better visual inspection but doesn’t prevent leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb23142f-2015-40a3-a532-f49b3d262306",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>Spectral Leakage: Why Endpoints Matter</h2>\n",
    "\n",
    "<img src=\"../images/spectral_leakage.png\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Problem:</strong> When using the FFT (Fast Fourier Transform), the algorithm assumes the input signal is <em>periodic</em> — meaning the end of the frame connects smoothly back to the start.</p>\n",
    "\n",
    "<p>If the <strong>start and end points are not equal</strong> (i.e., discontinuous), this creates a sudden jump — a sharp change that the FFT interprets as containing many high-frequency components.</p>\n",
    "\n",
    "<div style=\"border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;\">\n",
    "  <p><strong>Consequence:</strong> This artificial jump causes <strong>spectral leakage</strong>, where energy from a true frequency spreads into adjacent frequency bins. This results in a smeared spectrum.</p>\n",
    "</div>\n",
    "\n",
    "<h3>Why You Should Care</h3>\n",
    "<ul>\n",
    "  <li><strong>Music analysis:</strong> Makes it harder to detect clean harmonics and pitch</li>\n",
    "  <li><strong>Speech features:</strong> Leads to distorted MFCCs or spectral centroids</li>\n",
    "  <li><strong>Scientific signals:</strong> Introduces false frequencies that aren’t really there</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Solution</h3>\n",
    "<ul>\n",
    "  <li>Apply a <strong>windowing function</strong> (e.g., Hann, Hamming, Blackman)</li>\n",
    "  <li>This fades the signal smoothly to zero at both ends</li>\n",
    "  <li>Makes the signal appear more periodic → <strong>reduces spectral leakage</strong></li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"../images/spectral_leakage_2.png\">\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba40fb9c-d555-40bb-ac67-c7336a68a040",
   "metadata": {},
   "source": [
    "<h2>Frequency Domain Pipeline</h2>\n",
    "<img src=\"../images/frequency_domain_2.png\">\n",
    "<hr>\n",
    "<h2>Windowing</h2>\n",
    "<ul>\n",
    "  <li>Apply windowing function to each frame</li>\n",
    "  <li>Eliminates samples at both ends of a frame</li>\n",
    "  <li>Generates a periodic signal</li>\n",
    "</ul>\n",
    "<hr>\n",
    "<b>Hann Window</b>\n",
    "<img src=\"../images/hann_window.png\">\n",
    "<hr>\n",
    "<h2>Windowing by Hann function</h2>\n",
    "<img src=\"../images/windowing_hann.png\">\n",
    "<hr>\n",
    "<img src=\"../images/windowing_hann_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e06a9c7-3bff-4d05-9cc7-2ef717c90cd9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Problem: Non-Overlapping Frames + Hann Window</h3>\n",
    "\n",
    "<img src=\"../images/windowing_hann_3.png\">\n",
    "\n",
    "\n",
    "<p>When applying the <strong>Hann window</strong> to each frame of audio, the window tapers the signal down to <strong>zero at both ends</strong>. If frames are non-overlapping, this causes <strong>gaps of near-zero energy</strong> between frames.</p>\n",
    "\n",
    "<p>This leads to:</p>\n",
    "<ul>\n",
    "  <li>Loss of signal information between frames</li>\n",
    "  <li>Distortion in reconstructed signals</li>\n",
    "  <li>Artifacts in spectral analysis</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Solution: Use Overlapping Frames</h3>\n",
    "\n",
    "<p>To avoid gaps caused by windowing, we use overlapping frames — typically with <strong>50% overlap</strong> for Hann windows.</p>\n",
    "\n",
    "<p>This ensures that when the tapered parts of adjacent frames are summed, they reconstruct the original signal smoothly without gaps.</p>\n",
    "\n",
    "<p><strong>Result:</strong> Continuous energy, accurate frequency analysis, and smooth reconstruction.</p>\n",
    "\n",
    "<hr>\n",
    "<h3>Non Overlapping Frames</h3>\n",
    "<img src=\"../images/non_overlapping_frames.png\">\n",
    "<hr>\n",
    "<h3>Overlapping Frames</h3>\n",
    "<img src=\"../images/overlapping_frames.png\">\n",
    "<hr>\n",
    "<h3>Frequency-domain feature pipeline</h3>\n",
    "<img src=\"../images/frequency_domain_3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddce54e-771d-426b-9798-bdddc210943b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
